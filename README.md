# ğŸ¦œâ›“ï¸ LangChain Models 001

A comprehensive repository demonstrating the integration and usage of various embedding and language models with [LangChain](https://github.com/langchain-ai/langchain). This project showcases implementations across multiple providers including Azure OpenAI, Hugging Face, and Google APIs, with examples for both local and cloud-based inference.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://github.com/langchain-ai/langchain)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## âœ¨ Features

- **ğŸ”¤ Embedding Models**: Implementation of both Azure OpenAI and open-source embedding models
- **ğŸ¤– Language Models**: Support for various LLM providers (OpenAI, Google, Hugging Face)
- **ğŸ’¬ Chat Models**: Interactive chat implementations with different AI providers
- **ğŸ  Local & Cloud**: Examples for both local inference and API-based solutions
- **ğŸ”§ Easy Configuration**: Environment-based configuration management
- **ğŸ“Š Similarity Computing**: Built-in cosine similarity calculations for embeddings

---

## ğŸ“ Project Structure

```
Lang_Chain_models_001/
â”‚
â”œâ”€â”€ ğŸ“„ .env.example              # Environment variables template
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                 # Project documentation
â”œâ”€â”€ ğŸ“„ Project_001_langchain.py  # Main demonstration script
â”‚
â”œâ”€â”€ ğŸ“‚ EmbeddedModels/
â”‚   â”œâ”€â”€ ğŸ”¤ embed_open_ai.py      # Azure OpenAI embeddings
â”‚   â””â”€â”€ ğŸ”¤ embed_open_source.py  # Hugging Face embeddings
â”‚
â”œâ”€â”€ ğŸ“‚ LLMS/
â”‚   â””â”€â”€ ğŸ¤– llm_demo.py           # Language model demonstrations
â”‚
â””â”€â”€ ğŸ“‚ ChatModels/
    â”œâ”€â”€ ğŸ’» chatmodel_local_demo.py  # Local chat model
    â”œâ”€â”€ ğŸ”· chatmodels_openai.py     # OpenAI chat models
    â”œâ”€â”€ ğŸ” google_api_demo.py       # Google Gemini/PaLM
    â””â”€â”€ ğŸ¤— hugging_face_demo.py     # Hugging Face chat models
```

---

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone <repository-url>
cd Lang_Chain_models_001
```

### 2. Set Up Python Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables
```bash
# Copy the example environment file
cp .env.example .env

# Edit .env with your API keys and endpoints
nano .env  # or use your preferred editor
```

### 5. Run Your First Example
```bash
python Project_001_langchain.py
```

---

## ğŸ”‘ Environment Configuration

Create a `.env` file in the root directory with the following variables:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2023-12-01-preview
AZURE_DEPLOYMENT_NAME=your-deployment-name

# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key

# Hugging Face Configuration
HUGGINGFACEHUB_API_TOKEN=your_hugging_face_token

# OpenAI Configuration (if using direct OpenAI)
OPENAI_API_KEY=your_openai_api_key
```

> âš ï¸ **Important**: Never commit your `.env` file to version control. Add it to your `.gitignore`.

---

## ğŸ“š Module Documentation

### ğŸ”¤ Embedding Models

#### `EmbeddedModels/embed_open_ai.py`
- **Purpose**: Demonstrates Azure OpenAI embedding generation
- **Model**: `text-embedding-3-small`
- **Use Case**: High-quality text embeddings for semantic search and similarity tasks
- **Requirements**: Azure OpenAI subscription and deployment

```python
# Example usage
from EmbeddedModels.embed_open_ai import generate_embeddings
embeddings = generate_embeddings(["Hello world", "Goodbye world"])
```

#### `EmbeddedModels/embed_open_source.py`
- **Purpose**: Local embedding generation using Hugging Face models
- **Model**: `sentence-transformers/all-MiniLM-L6-v2`
- **Use Case**: Privacy-focused, offline embedding generation
- **Requirements**: Sufficient local compute resources

### ğŸ¤– Language Models

#### `LLMS/llm_demo.py`
- **Purpose**: Basic LLM interaction examples
- **Features**: Text generation, completion, and prompt engineering
- **Customizable**: Easy to switch between different LLM providers

### ğŸ’¬ Chat Models

#### `ChatModels/chatmodel_local_demo.py`
- **Purpose**: Local conversational AI using Hugging Face transformers
- **Model**: GPT-2 or other local models
- **Benefits**: No API costs, full privacy control

#### `ChatModels/chatmodels_openai.py`
- **Purpose**: OpenAI GPT models for conversational AI
- **Features**: Advanced chat capabilities with context management
- **Models**: GPT-3.5-turbo, GPT-4, etc.

#### `ChatModels/google_api_demo.py`
- **Purpose**: Google's Gemini and PaLM models integration
- **Features**: Multimodal capabilities (text, images)
- **Benefits**: Competitive pricing and performance

#### `ChatModels/hugging_face_demo.py`
- **Purpose**: Hugging Face Hub models for chat and text generation
- **Flexibility**: Access to thousands of community models
- **Options**: Both API and local inference

---

## ğŸ¯ Usage Examples

### Basic Embedding Generation
```bash
python EmbeddedModels/embed_open_ai.py
```

### Local Chat Model
```bash
python ChatModels/chatmodel_local_demo.py
```

### Similarity Search Demo
```bash
python Project_001_langchain.py
```

---

## ğŸ› ï¸ Customization Guide

### Adding New Models
1. Create a new Python file in the appropriate directory
2. Import necessary LangChain components
3. Configure your model with environment variables
4. Follow the existing code patterns for consistency

### Switching Embedding Models
```python
# In embed_open_ai.py, change:
embeddings = AzureOpenAIEmbeddings(
    model="text-embedding-3-large"  # Upgrade to larger model
)
```

### Adding New Providers
1. Install provider-specific packages
2. Add API keys to `.env`
3. Create demonstration script following existing patterns

---

## ğŸ“Š Performance Considerations

| Model Type | Provider | Speed | Cost | Quality | Privacy |
|------------|----------|-------|------|---------|---------|
| Embeddings | Azure OpenAI | âš¡âš¡âš¡ | ğŸ’°ğŸ’° | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸ”’ğŸ”’ |
| Embeddings | Hugging Face (Local) | âš¡âš¡ | ğŸ’° | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸ”’ğŸ”’ğŸ”’ğŸ”’ğŸ”’ |
| Chat | GPT-4 | âš¡âš¡ | ğŸ’°ğŸ’°ğŸ’° | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸ”’ğŸ”’ |
| Chat | Local Models | âš¡ | ğŸ’° | ğŸŒŸğŸŒŸğŸŒŸ | ğŸ”’ğŸ”’ğŸ”’ğŸ”’ğŸ”’ |

---

## ğŸš¨ Troubleshooting

### Common Issues

**1. API Key Errors**
```bash
Error: Invalid API key
```
- Verify your API keys in `.env`
- Check key permissions and quotas
- Ensure correct endpoint URLs

**2. Model Loading Issues**
```bash
Error: Model not found
```
- Check internet connection for downloads
- Verify sufficient disk space for local models
- Update model names to current versions

**3. Memory Issues**
```bash
CUDA out of memory
```
- Use smaller models for local inference
- Reduce batch sizes
- Consider using CPU instead of GPU

### Getting Help
- Check the [LangChain Documentation](https://python.langchain.com/docs/)
- Review provider-specific documentation
- Open an issue in this repository

---

## ğŸ“‹ Requirements

### System Requirements
- Python 3.8 or higher
- 4GB+ RAM (8GB+ recommended for local models)
- Internet connection for API-based models

### API Access Requirements
- Azure OpenAI: Active subscription and deployed models
- Google AI: Valid API key with enabled services
- Hugging Face: API token for Hub access (optional for public models)

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Contribution Guidelines
- Follow existing code style and patterns
- Add documentation for new features
- Include example usage for new models
- Test your changes across different environments

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain) - The amazing framework that makes this all possible
- [Hugging Face](https://huggingface.co/) - For democratizing AI and providing excellent models
- [OpenAI](https://openai.com/) - For advancing the field of AI
- [Google AI](https://ai.google.dev/) - For innovative AI research and development

---

## ğŸ“ Contact & Support

**Author**: Adil Usmani

- ğŸ“§ Email: [muhammadaadilusmani@gmail.com]
- ğŸ™ GitHub: [AadilUsmani]
- ğŸ’¼ LinkedIn: [Adil Usmani]

---

## ğŸ”„ Version History

- **v1.0.0** - Initial release with basic model implementations
- **v1.1.0** - Added Google AI integration
- **v1.2.0** - Enhanced documentation and examples

---

*Made with â¤ï¸ and LangChain*